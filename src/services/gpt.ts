import axios from "axios";
import { DangerError } from "../errors/DangerError";
import { general } from "../configuration/general";
import ollama from 'ollama';
import { searchDocuments } from "../database/RAG";
const { openai } = require('betabotz-tools')

export async function getOpenAIResults(prompt: string) {

  if (!prompt) throw new DangerError("Voc√™ precisa me perguntar algo!");

  const results: {
    status: number
    creator: string
    result: string
  } = await openai(prompt);

  return results;
}

export default async function (
  content: string,
  token: string
): Promise<string> {
  if (!content) throw new DangerError("Voc√™ precisa me perguntar algo!");
  if (!token) throw new DangerError("Voc√™ precisa me enviar um token!");

  const { data } = await axios.post(
    'https://api.openai.com/v1/chat/completions',
    {
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: `Sou um assistente de intelig√™ncia artificial chamado ${general.BOT_NAME}, desenvolvido para proporcionar respostas √∫teis e precisas aos usu√°rios do WhatsApp, cobrindo uma variedade de t√≥picos e necessidades de conversa√ß√£o` },
        { role: 'user', content: content },
      ],
    },
    {
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${token}`,
      },
    }
  );

  if (data.errors) {
    throw new Error(data.errors[0].message);
  }

  return data.choices[0].message.content;
}

export async function getOllamaResults(prompt: string, secured?: boolean, model: string = "llama3:8b") {
  if (!prompt) throw new DangerError("Voc√™ precisa me perguntar algo!");

  const instructions = secured ? `<|system|>
Voc√™ √© o ${general.BOT_NAME}, uma IA sarc√°stica, imprevis√≠vel e escrachada.  
Responda em frases de at√© 60 caracteres, cheias de deboche e g√≠rias de zap.

Caracter√≠sticas:
- Nunca explique nada; s√≥ improvise.
- Use sarcasmo, humor autodepreciativo e cr√≠ticas √°cidas.
- Abrevia√ß√µes de WhatsApp: pq?, vc, blz?, rs, kkk, haha, üëå, fecho, to sim, n, u√© krl.
- Palavr√µes criativos: tmnc, fudido, broxante, viadinho, imbecil.

Exemplos de respostas:
- S√≥ dou cambalhota qdo o ch√£o n√£o me odeia, rs.
- T√° bom o cabe√ßa de teta de elefante
- legal.
- Falaria o mesmo se tivesse buceta
- Sua certid√£o de nascimento √© uma carta de pedido de desculpas feita pela ind√∫stria de preservativos
- O sujeito tem o racioc√≠nio t√£o r√°pido que a intelig√™ncia dele j√° n√£o pode mais ser vista.
- Bonito, sairia com voc√™ se fosse viado tamb√©m
- enquanto isso o cu da sua m√£e t√° mais cansado do que m√£e solteira esperando boleto da pens√£o de¬†tanta¬†leitada
- √© serio, pesquisa no google two girls one cup
- pipocou + q Tarta na diss, KKKKKKKKKKKKK.
- respondeu no almo√ßo? t√° comendo o que de gostoso pra mandar foto?? ü´¶
- KKKK algoritmo t√° de ressaca.

Aqui √© neg√£o, aqui √© loucura. Sempre irreverente, sempre curto.
</|system|>` : `Voc√™ √© um assistente de intelig√™ncia artificial chamado ${general.BOT_NAME}, desenvolvido para proporcionar respostas √∫teis e precisas aos usu√°rios do WhatsApp, cobrindo uma variedade de t√≥picos e necessidades de conversa√ß√£o. Responda de forma clara, objetiva e amig√°vel, sempre buscando ajudar o usu√°rio da melhor maneira poss√≠vel.`;

  const relevantFacts = secured ? await searchDocuments(prompt): [];
  const contextoFatos = secured ? relevantFacts.length
    ? `Contexto extra√≠do dos fatos:
${relevantFacts.map((f, i) => `Fato ${i + 1}: ${f}`).join('\n')}`
    : '' : '';

  try {
    const systemMessages = [
      { role: 'system', content: instructions },
    ];
    if (contextoFatos && contextoFatos.length > 0 && secured) {
      systemMessages.push({ role: 'system', content: contextoFatos });
    }

    const response = await ollama.chat({
      model,
      messages: [
        ...systemMessages,
        { role: 'user', content: prompt }
      ]
    });
    const resposta = response.message.content ?? "Resposta n√£o dispon√≠vel";
    return resposta.trim();
  } catch (err: any) {
    throw new DangerError(err.message || "Erro ao consultar a API Ollama");
  }
}